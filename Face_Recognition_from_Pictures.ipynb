{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d16b176-98d4-4350-ba3c-91ffc0bf4c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from -r requirements.txt (line 1)) (1.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from -r requirements.txt (line 2)) (1.21.4)\n",
      "Requirement already satisfied: dlib in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from -r requirements.txt (line 3)) (19.22.1)\n",
      "Requirement already satisfied: face_recognition in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from -r requirements.txt (line 5)) (4.5.4.58)\n",
      "Requirement already satisfied: imutils in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from -r requirements.txt (line 6)) (0.5.4)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from face_recognition->-r requirements.txt (line 4)) (8.0.3)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from face_recognition->-r requirements.txt (line 4)) (0.3.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from face_recognition->-r requirements.txt (line 4)) (8.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from Click>=6.0->face_recognition->-r requirements.txt (line 4)) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from pandas->-r requirements.txt (line 1)) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\russe\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f58b0f8-167e-4553-9e7b-54b42c2589eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c1f6f1-193e-48ba-90a7-b3c36c7b58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns (R, G, B) from name\n",
    "def name_to_color(name):\n",
    "    # Take 3 first letters, tolower()\n",
    "    # lowercased character ord() value rage is 97 to 122, substract 97, multiply by 8\n",
    "    color = [((ord(c.lower())-97)*8) +10 for c in name[:3]]\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d6fb51-1006-4dee-b658-3750de8b022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize images while maintaining image quality\n",
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f04689-e963-4a3b-849f-816598ec7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify Code for Video Stream image capture\n",
    "\n",
    "KNOWN_FACES_DIR = 'dataset/Known_faces'\n",
    "UNKNOWN_FACES_DIR = 'dataset/Unknown_faces'\n",
    "TOLERANCE = 0.55 # Lower == More Strict\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 1\n",
    "MODEL = 'cnn'  # 'hog' or 'cnn' - CUDA accelerated (if available) deep-learning pretrained model\n",
    "\n",
    "known_faces = []\n",
    "known_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb2d27a-e1c0-4d65-9e19-342a87dfc0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading known faces...\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and Encode Known Faces as base for comparison\n",
    "print('Loading known faces...')\n",
    "for name in os.listdir(KNOWN_FACES_DIR):\n",
    "    # Next we load every file of faces of known person\n",
    "    for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n",
    "        # Load an image\n",
    "        image = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}/{name}/{filename}')\n",
    "        # Get 128-dimension face encoding\n",
    "        # face_recognition always returns a list of found faces, for this purpose we take first face only\n",
    "        # (assuming one face per image in Known_faces as a single person can't appear twice in one image)\n",
    "        encoding = face_recognition.face_encodings(image)[0]\n",
    "        # Append encodings and name\n",
    "        known_faces.append(encoding)\n",
    "        known_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210ef0b-8505-4ea7-8e8b-c8dd0fb80b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Unknown Faces Library\n",
    "print('Processing unknown faces...')\n",
    "# Now let's loop over a folder of faces we want to label\n",
    "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
    "    \n",
    "    # Load image\n",
    "    print(f'Filename {filename}', end='')\n",
    "    image = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}/{filename}') # Grab image from directory\n",
    "    locations = face_recognition.face_locations(image, model=MODEL) # grab face locations - we'll need them to draw boxes\n",
    "    encodings = face_recognition.face_encodings(image, locations) # Pass face locations to be encoded so that model does not need to search again\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # convert it from RGB to BGR as we are going to work with cv2\n",
    "    # We assume that there might be more faces in an image - let's find the faces of different people\n",
    "    print(f', found {len(encodings)} face(s)')\n",
    "    for face_encoding, face_location in zip(encodings, locations): \n",
    "\n",
    "        # We use compare_faces (but can use face_distance for distance-score measurement as well)\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE) # Returns array of True/False values in order of passed known_faces\n",
    "        # Order is preserved, so we check if any face was found then grab its index, then label (name) of first matching known face withing a tolerance\n",
    "        match = None\n",
    "        if True in results:  # If at least one is true, get a name of first of found labels\n",
    "            match = known_names[results.index(True)]\n",
    "            print(f' - {match} from {results}')\n",
    "            # Each location contains positions in order: top, right, bottom, left\n",
    "            top_left = (face_location[3], face_location[0])\n",
    "            bottom_right = (face_location[1], face_location[2])\n",
    "            # Get color by name using our fancy function\n",
    "            color = name_to_color(match)\n",
    "            # Paint frame\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "            # Create a smaller, filled frame below for a name\n",
    "            top_left = (face_location[3], face_location[2])\n",
    "            bottom_right = (face_location[1], face_location[2] + 22) # This time we use bottom in both corners - to start from bottom and move 50 pixels down\n",
    "            # Paint frame\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "            # Wite a name\n",
    "            cv2.putText(image, match, (face_location[3] + 10, face_location[2] + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), FONT_THICKNESS)\n",
    "\n",
    "    # Show image\n",
    "    resize = ResizeWithAspectRatio(image, width=850) # Resize by width OR\n",
    "#     resize = ResizeWithAspectRatio(image, height=1980) # Resize by height\n",
    "    cv2.imshow(filename, resize)\n",
    "    cv2.waitKey(0) \n",
    "    cv2.destroyWindow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da778f-1ce7-4f60-a1ef-02e8bb70485b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45927b03-a7e2-4071-a1c5-c2f951881694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_env",
   "language": "python",
   "name": "face_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
